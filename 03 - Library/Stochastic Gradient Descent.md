>[!DEFINITION ] Definition
> Stochastic Gradient Descent (SGD for short) is an iterative method for optimizing the objective function. It is a stochastic approximation of the [Gradient Descent] algorithm


